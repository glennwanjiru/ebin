{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7308195,
          "sourceType": "datasetVersion",
          "datasetId": 4240454
        },
        {
          "sourceId": 7327940,
          "sourceType": "datasetVersion",
          "datasetId": 4215516
        },
        {
          "sourceId": 7328638,
          "sourceType": "datasetVersion",
          "datasetId": 4215355
        }
      ],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glennwanjiru/ebin/blob/main/converted%20and%20downloadVGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'test-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4215516%2F7327940%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240325%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240325T095719Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4419d1aa4ca2e0019536ec3c652425b6dec11d81ee4fd7b2e4dc76df7790cd941266d80f4767bb6a294b9b808930f9673483da8ae2d6718080db0faa147e60e1702e33b6376a0f5e4d4f3f9d50b0edb33faffbb94e6a45e6831930cd89bcb077ea1130317ba545ce8171ab04b374458e5a3284a5824250afe3d8b74917cafa4949c761499dd092e4d9753e45c3f1a94f1cc73806419e3ded48d238c4cbc278e867b068a8c4dc42c86c9a8ad9f8eee806bf3f2f1e7f1ffb9bdda873ffdce6bc7fae1a1731d914ce891315743dff1fa9cc7332d3a3b3245b23724a930ddabc3b079ca89c07007b9cf22d0193ebbece5ddf712ca9e52c224ae16cf9e1187777418a,garbage-classification-6-classes-775class:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4215355%2F7328638%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240325%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240325T095719Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1a48d642fb27b4d05b79eb9405636430d9722c97b4d02dec5b722fa1eb7c7d6e5e95934197814e742aa68308f7530be63ee4ceace948a9c37c6f2dc6028db2e84aa5d0e3c141c5eec8f80f4544323ba2c6f0aae50b3056769e8add6d3ab29fa4deb6779ad34c3287286df28ba61cf45313179f94b2548693547218a1bfa28762e051da6348cfbb7c4a035dcd16aa729e0eaffe5972955049c07b9019180bbd891431ed0c5df47df5080eebf1d42a80d089d56729cda252556a3c627359d52947028e3106e8fd21a5bc61c6b2ca53e30d5a042ede2338de353c7548810efd9d2181e57eb4f61bea4954eb6be913c3e4b0870c6f0e6ea4d1049cf768fce659681e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHrFBfrqC0Kx",
        "outputId": "aa40bb65-bf29-4a53-f928-053a9b69cc28"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading test-data, 258923 bytes compressed\n",
            "[==================================================] 258923 bytes downloaded\n",
            "Downloaded and uncompressed: test-data\n",
            "Downloading garbage-classification-6-classes-775class, 52632139 bytes compressed\n",
            "[==================================================] 52632139 bytes downloaded\n",
            "Downloaded and uncompressed: garbage-classification-6-classes-775class\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install -q seaborn\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from PIL import Image\n",
        "BATCH_SIZE = 64\n",
        "n_classes = 6\n",
        "\n",
        "# VGG16 base model\n",
        "conv_base = VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Freeze all layers except the last two\n",
        "for layer in conv_base.layers[:-2]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Top model\n",
        "top_model = conv_base.output\n",
        "top_model = Flatten(name=\"flatten\")(top_model)\n",
        "top_model = Dense(1024, activation='relu')(top_model)  # Increased units\n",
        "top_model = BatchNormalization()(top_model)\n",
        "top_model = Dropout(0.5)(top_model)\n",
        "top_model = Dense(512, activation='relu')(top_model)  # Increased units\n",
        "top_model = BatchNormalization()(top_model)\n",
        "top_model = Dropout(0.5)(top_model)\n",
        "output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "\n",
        "# Final Model\n",
        "model = Model(inputs=conv_base.input, outputs=output_layer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T04:10:08.514248Z",
          "iopub.execute_input": "2024-01-03T04:10:08.514538Z",
          "iopub.status.idle": "2024-01-03T04:10:48.358851Z",
          "shell.execute_reply.started": "2024-01-03T04:10:08.514513Z",
          "shell.execute_reply": "2024-01-03T04:10:48.35804Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9O5waWEC0K1",
        "outputId": "48a31b0d-43ff-4d54-c126-4c3010dbdac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_random_images(generator, num_images=20):\n",
        "    # Get a batch of data from the generator\n",
        "    images, labels = next(generator)\n",
        "\n",
        "    # Get random indices for selecting images\n",
        "    random_indices = np.random.choice(images.shape[0], num_images, replace=False)\n",
        "\n",
        "    # Plot the selected images\n",
        "    fig, axs = plt.subplots(4, 5, figsize=(15, 12))\n",
        "    fig.suptitle('Random 20 Images from the Generator', fontsize=16)\n",
        "\n",
        "    for i, ax in enumerate(axs.flatten()):\n",
        "        index = random_indices[i]\n",
        "        image = images[index]\n",
        "        label = labels[index]\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f'Class: {np.argmax(label)}')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "_AQhDUI-C0K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/kaggle/input/garbage-classification-6-classes-775class'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:51:47.639744Z",
          "iopub.execute_input": "2024-01-03T01:51:47.640163Z",
          "iopub.status.idle": "2024-01-03T01:51:47.645229Z",
          "shell.execute_reply.started": "2024-01-03T01:51:47.640134Z",
          "shell.execute_reply": "2024-01-03T01:51:47.644178Z"
        },
        "trusted": true,
        "id": "FcylucyLC0K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data = ImageDataGenerator(rescale=1./255).flow_from_directory(data_path, target_size = (224, 224), batch_size = BATCH_SIZE, class_mode=\"categorical\")\n",
        "plot_random_images(original_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:51:47.818576Z",
          "iopub.execute_input": "2024-01-03T01:51:47.818912Z",
          "iopub.status.idle": "2024-01-03T01:51:50.035159Z",
          "shell.execute_reply.started": "2024-01-03T01:51:47.818888Z",
          "shell.execute_reply": "2024-01-03T01:51:50.034191Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuCaKk8sC0K3",
        "outputId": "775856b2-bde3-497f-e47d-4486bc8ad5a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4650 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_train = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
        "full_data = gen_train.flow_from_directory(data_path, target_size = (224, 224), batch_size = BATCH_SIZE, class_mode=\"categorical\")\n",
        "plot_random_images(full_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:51:50.037127Z",
          "iopub.execute_input": "2024-01-03T01:51:50.037496Z",
          "iopub.status.idle": "2024-01-03T01:51:52.140791Z",
          "shell.execute_reply.started": "2024-01-03T01:51:50.037463Z",
          "shell.execute_reply": "2024-01-03T01:51:52.139881Z"
        },
        "trusted": true,
        "id": "OPp31xhCC0K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract filenames and labels from the DirectoryIterator\n",
        "filenames = full_data.filenames\n",
        "labels = full_data.labels\n",
        "class_mapping = {value: str(key) for key, value in full_data.class_indices.items()}\n",
        "labels = [class_mapping[label] for label in labels]\n",
        "\n",
        "filenames[:5], labels[:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:51:52.142176Z",
          "iopub.execute_input": "2024-01-03T01:51:52.142551Z",
          "iopub.status.idle": "2024-01-03T01:51:52.166828Z",
          "shell.execute_reply.started": "2024-01-03T01:51:52.14252Z",
          "shell.execute_reply": "2024-01-03T01:51:52.165768Z"
        },
        "trusted": true,
        "id": "YGp3rc4lC0K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_filenames, test_filenames, train_labels, test_labels = train_test_split(\n",
        "    filenames, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Create DataFrames for training and testing\n",
        "train_df = pd.DataFrame({'filename': train_filenames, 'class': train_labels})\n",
        "test_df = pd.DataFrame({'filename': test_filenames, 'class': test_labels})\n",
        "\n",
        "# Create separate generators for training and testing using flow_from_dataframe\n",
        "train_data = gen_train.flow_from_dataframe(train_df, directory=data_path, target_size=(224, 224),\n",
        "                                           batch_size=BATCH_SIZE, class_mode=\"categorical\",\n",
        "                                           shuffle=True, seed=42)\n",
        "\n",
        "test_data = gen_train.flow_from_dataframe(test_df, directory=data_path, target_size=(224, 224),\n",
        "                                          batch_size=BATCH_SIZE, class_mode=\"categorical\",\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:51:52.16948Z",
          "iopub.execute_input": "2024-01-03T01:51:52.170138Z",
          "iopub.status.idle": "2024-01-03T01:51:54.29163Z",
          "shell.execute_reply.started": "2024-01-03T01:51:52.170102Z",
          "shell.execute_reply": "2024-01-03T01:51:54.290754Z"
        },
        "trusted": true,
        "id": "pUJHhAE3C0K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200\n",
        "opt = Adam(lr=0.0001)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='model.best.h5',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "early = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T02:15:10.10188Z",
          "iopub.execute_input": "2024-01-03T02:15:10.102544Z",
          "iopub.status.idle": "2024-01-03T02:15:10.427519Z",
          "shell.execute_reply.started": "2024-01-03T02:15:10.102517Z",
          "shell.execute_reply": "2024-01-03T02:15:10.426258Z"
        },
        "trusted": true,
        "id": "cDB7jQ6OC0K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:51:54.308721Z",
          "iopub.execute_input": "2024-01-03T01:51:54.30907Z",
          "iopub.status.idle": "2024-01-03T01:51:54.374863Z",
          "shell.execute_reply.started": "2024-01-03T01:51:54.309038Z",
          "shell.execute_reply": "2024-01-03T01:51:54.373788Z"
        },
        "trusted": true,
        "id": "xHMHzjV3C0K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = train_data.samples // BATCH_SIZE\n",
        "n_val_steps = test_data.samples // BATCH_SIZE\n",
        "n_steps, n_val_steps"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:54:45.736137Z",
          "iopub.execute_input": "2024-01-03T01:54:45.736916Z",
          "iopub.status.idle": "2024-01-03T01:54:45.743579Z",
          "shell.execute_reply.started": "2024-01-03T01:54:45.736882Z",
          "shell.execute_reply": "2024-01-03T01:54:45.74235Z"
        },
        "trusted": true,
        "id": "LECMd2SvC0K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(\n",
        "    train_data,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=test_data,\n",
        "    validation_steps=n_val_steps,\n",
        "    callbacks=[early, checkpoint, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T01:55:02.743723Z",
          "iopub.execute_input": "2024-01-03T01:55:02.744821Z",
          "iopub.status.idle": "2024-01-03T01:56:25.808184Z",
          "shell.execute_reply.started": "2024-01-03T01:55:02.744782Z",
          "shell.execute_reply": "2024-01-03T01:56:25.806575Z"
        },
        "trusted": true,
        "id": "TD5ea6SFC0K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Accuracy\")\n",
        "plt.plot(result.history[\"accuracy\"])\n",
        "plt.plot(result.history[\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:38:58.881976Z",
          "iopub.execute_input": "2024-01-03T00:38:58.882977Z",
          "iopub.status.idle": "2024-01-03T00:38:59.138853Z",
          "shell.execute_reply.started": "2024-01-03T00:38:58.882937Z",
          "shell.execute_reply": "2024-01-03T00:38:59.1379Z"
        },
        "trusted": true,
        "id": "w8Y3wA9bC0K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Loss\")\n",
        "plt.plot(result.history[\"loss\"])\n",
        "plt.plot(result.history[\"val_loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:38:49.395106Z",
          "iopub.execute_input": "2024-01-03T00:38:49.395518Z",
          "iopub.status.idle": "2024-01-03T00:38:49.713447Z",
          "shell.execute_reply.started": "2024-01-03T00:38:49.39548Z",
          "shell.execute_reply": "2024-01-03T00:38:49.712558Z"
        },
        "trusted": true,
        "id": "2O_NJKNnC0K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:37:41.965721Z",
          "iopub.execute_input": "2024-01-03T00:37:41.966113Z",
          "iopub.status.idle": "2024-01-03T00:37:42.332748Z",
          "shell.execute_reply.started": "2024-01-03T00:37:41.966083Z",
          "shell.execute_reply": "2024-01-03T00:37:42.331746Z"
        },
        "trusted": true,
        "id": "IO5JQ-WvC0K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:30:31.289802Z",
          "iopub.execute_input": "2024-01-03T00:30:31.290164Z",
          "iopub.status.idle": "2024-01-03T00:30:31.420357Z",
          "shell.execute_reply.started": "2024-01-03T00:30:31.290138Z",
          "shell.execute_reply": "2024-01-03T00:30:31.419505Z"
        },
        "trusted": true,
        "id": "g1fMcqd5C0K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Get the predicted class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true class labels\n",
        "true_labels = test_data.classes\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=test_data.class_indices.keys(),\n",
        "            yticklabels=test_data.class_indices.keys())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "class_names = list(test_data.class_indices.keys())\n",
        "print(classification_report(true_labels, predicted_labels, target_names=class_names))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:30:41.723829Z",
          "iopub.execute_input": "2024-01-03T00:30:41.724197Z",
          "iopub.status.idle": "2024-01-03T00:30:57.850706Z",
          "shell.execute_reply.started": "2024-01-03T00:30:41.72417Z",
          "shell.execute_reply": "2024-01-03T00:30:57.849792Z"
        },
        "trusted": true,
        "id": "PVn880iMC0K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_class = [\"battery\", \"glass\", \"metal\",\"organic\", \"paper\", \"plastic\"]\n",
        "\n",
        "def preprocessing_input(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img) # VGG16 preprocess_input\n",
        "    return img\n",
        "\n",
        "def plot_images(original, preprocessed):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    axs[0].imshow(original)\n",
        "    axs[0].set_title('Original Image')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    # Remove the batch dimension for display\n",
        "    preprocessed = np.squeeze(preprocessed, axis=0)\n",
        "\n",
        "    axs[1].imshow(preprocessed)\n",
        "    axs[1].set_title('Preprocessed Image')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def predict_user(img_path):\n",
        "    img = preprocessing_input(img_path)\n",
        "    plot_images(Image.open(img_path), img)\n",
        "    predicted_array = model.predict(img)\n",
        "    predicted_value = output_class[np.argmax(predicted_array)]\n",
        "    predicted_accuracy = round(np.max(predicted_array) * 100, 2)\n",
        "    print(\"Your waste material is\", predicted_value, \"with\", predicted_accuracy, \"% accuracy.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:53:11.332709Z",
          "iopub.execute_input": "2024-01-03T00:53:11.333828Z",
          "iopub.status.idle": "2024-01-03T00:53:11.342626Z",
          "shell.execute_reply.started": "2024-01-03T00:53:11.333769Z",
          "shell.execute_reply": "2024-01-03T00:53:11.341692Z"
        },
        "trusted": true,
        "id": "eAoTWOdtC0K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_user('/kaggle/input/test-data/61238183.jpg')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-03T00:54:01.886668Z",
          "iopub.execute_input": "2024-01-03T00:54:01.887642Z",
          "iopub.status.idle": "2024-01-03T00:54:02.300559Z",
          "shell.execute_reply.started": "2024-01-03T00:54:01.887604Z",
          "shell.execute_reply": "2024-01-03T00:54:02.299601Z"
        },
        "trusted": true,
        "id": "2vTtbF9vC0K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf2onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c860Rc64s3N",
        "outputId": "22cd1de5-1c94-4530-ffa4-f5470f3644ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/455.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/455.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m450.6/455.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.25.2)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.7)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.2.2)\n",
            "Installing collected packages: onnx, tf2onnx\n",
            "Successfully installed onnx-1.16.0 tf2onnx-1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49NauX7eBODD",
        "outputId": "84f47bcd-cf4e-4f80-b19c-5cb4c48b9306"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tf2onnx import convert\n",
        "\n",
        "# Load the TensorFlow model\n",
        "model = tf.keras.models.load_model(\"/content/model.vgg19.h5\")\n",
        "\n",
        "# Convert the model to ONNX format\n",
        "onnx_model, _ = convert.from_keras(model)\n",
        "\n",
        "# Save the ONNX model to a file\n",
        "onnx_model_path = \"model.onnx\"\n",
        "with open(onnx_model_path, \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(f\"ONNX model saved to {onnx_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp2QI06O4oQc",
        "outputId": "24c4f30a-51cd-4494-89c2-c08875efcf1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model saved to model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Define the path to the ONNX model file\n",
        "onnx_model_path = \"/content/vgg19.onnx\"\n",
        "\n",
        "# Download the ONNX model file\n",
        "files.download(onnx_model_path)\n"
      ],
      "metadata": {
        "id": "mkT4ODPRDOb6",
        "outputId": "dcb0a905-db59-45f8-d0ad-3fb99c8a54fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7ef67a1c-c785-4205-9403-39b4212f96a6\", \"vgg19.onnx\", 574678146)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}